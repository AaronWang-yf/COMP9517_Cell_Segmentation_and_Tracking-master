{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"JNet.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"JLXIh68JNEnS","colab_type":"text"},"source":["More information is available at: https://drive.google.com/drive/folders/1EkcRgZZmvGKJ1xrUgf047DSvd98mfYHi?usp=sharing"]},{"cell_type":"code","metadata":{"id":"4sQJ4VSHiAd7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"status":"ok","timestamp":1596606097888,"user_tz":-600,"elapsed":10657,"user":{"displayName":"Raymond Lu","photoUrl":"","userId":"03985932570144233795"}},"outputId":"c43e21a3-092c-4a3d-d1a6-d20afd71836c"},"source":["!pip install imagecodecs"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting imagecodecs\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/d0/09edd29531c81bb95919a687c14eafaf9867fdefabfdafc27b139434a394/imagecodecs-2020.5.30-cp36-cp36m-manylinux2014_x86_64.whl (17.9MB)\n","\u001b[K     |████████████████████████████████| 17.9MB 1.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.6/dist-packages (from imagecodecs) (1.18.5)\n","Installing collected packages: imagecodecs\n","Successfully installed imagecodecs-2020.5.30\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9z5C3DG2zf0S","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1596606155984,"user_tz":-600,"elapsed":52746,"user":{"displayName":"Raymond Lu","photoUrl":"","userId":"03985932570144233795"}},"outputId":"545d241f-0423-46fa-ce7d-055b2e54915f"},"source":["!pip uninstall torch"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Uninstalling torch-1.6.0+cu101:\n","  Would remove:\n","    /usr/local/bin/convert-caffe2-to-onnx\n","    /usr/local/bin/convert-onnx-to-caffe2\n","    /usr/local/lib/python3.6/dist-packages/caffe2/*\n","    /usr/local/lib/python3.6/dist-packages/torch-1.6.0+cu101.dist-info/*\n","    /usr/local/lib/python3.6/dist-packages/torch/*\n","Proceed (y/n)? y\n","  Successfully uninstalled torch-1.6.0+cu101\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I8nAd8d-jFM4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"executionInfo":{"status":"ok","timestamp":1596606239014,"user_tz":-600,"elapsed":48422,"user":{"displayName":"Raymond Lu","photoUrl":"","userId":"03985932570144233795"}},"outputId":"a1cf0668-f3f2-4713-b05a-725180054e0d"},"source":["!pip install torch==0.4.1"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting torch==0.4.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n","\u001b[K     |████████████████████████████████| 519.5MB 31kB/s \n","\u001b[31mERROR: torchvision 0.7.0+cu101 has requirement torch==1.6.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: fastai 1.0.61 has requirement torch>=1.0.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n","\u001b[?25hInstalling collected packages: torch\n","Successfully installed torch-0.4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vR2ohCmSbUWb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1596606272404,"user_tz":-600,"elapsed":19814,"user":{"displayName":"Raymond Lu","photoUrl":"","userId":"03985932570144233795"}},"outputId":"c6d6a419-035a-4773-a497-1efff86526cc"},"source":["from google.colab import drive \n","drive.mount(\"/content/gdrive\") "],"execution_count":5,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"voOY1aZ5bnxZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596606274403,"user_tz":-600,"elapsed":778,"user":{"displayName":"Raymond Lu","photoUrl":"","userId":"03985932570144233795"}}},"source":["import os \n","os.chdir(\"/content/gdrive/My Drive/comp9517/project/jnet-master\")"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i-ImqGpjNT-k","colab_type":"text"},"source":["The training takes almost one day on Google Colab Pro. And the parameters of the trained model are saved in a hidden folder. I mistakenly clicked the running button, and the training log is gone now. You can see that the code loads the parameter from the hidden folder, and since the first epoch the loss is very small already."]},{"cell_type":"code","metadata":{"id":"9wXMEdKQbxrp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596607170932,"user_tz":-600,"elapsed":162311,"user":{"displayName":"Raymond Lu","photoUrl":"","userId":"03985932570144233795"}},"outputId":"b67a502b-6080-45f5-d55e-87538eefecae"},"source":["!python3 main.py --cuda --images_idx '{\"01\":[\"002\",\"005\",\"021\",\"031\",\"033\",\"034\",\"039\",\"054\",\"067\"],\"02\":[\"006\",\"007\",\"014\",\"027\",\"034\",\"038\",\"042\",\"061\",\"067\"]}' --load_dataset_to_ram 1 --num_workers -1 --dataset_len_multiplier 16 --batch_size 8 --resolution_levels \"[-2,-1,0]\" --aug_rotation_flip --aug_elastic_params \"[(50,5,5),(-1,-1,1)]\" --structure \"[[16,64,3],[2,8,3],[2,8,3]]\" --dt_bound 6 --validation_percentage 0.17 --learning_rate 0.00003 --mode train --output_dir results/DIC-C2DH-HeLa6"],"execution_count":14,"outputs":[{"output_type":"stream","text":["==================================args=============================\n","Namespace(aug_crop_params='[]', aug_elastic_params='[(50,5,5),(-1,-1,1)]', aug_intensity_params='[]', aug_rotation=False, aug_rotation_flip=True, batch_size=8, batchnorm_momentum=0.1, cuda=True, dataset_len_multiplier=16, dataset_root='/content/gdrive/My Drive/comp9517/project/jnet-master/toyexample/DIC-C2DH-HeLa_training', dt_bound=6, images_idx='{\"01\":[\"002\",\"005\",\"021\",\"031\",\"033\",\"034\",\"039\",\"054\",\"067\"],\"02\":[\"006\",\"007\",\"014\",\"027\",\"034\",\"038\",\"042\",\"061\",\"067\"]}', learning_rate=3e-05, load_dataset_to_ram=1, mode=<Mode.Train: 'train'>, model_file='', non_decreasing_output_file='', num_epochs=3000, num_workers=-1, output_dir='results/DIC-C2DH-HeLa6', resolution_levels='[-2,-1,0]', save_model_frequency=200, structure='[[16,64,3],[2,8,3],[2,8,3]]', validation_percentage=0.17)\n","================================end args===========================\n","CUDA: True True\n","===Eval command best train===\n","python3 main.py --cuda --resolution_levels '[-2,-1,0]' --dt_bound 6 --images_idx '{\"01\":[\"002\",\"005\",\"021\",\"031\",\"033\",\"034\",\"039\",\"054\",\"067\"],\"02\":[\"006\",\"007\",\"014\",\"027\",\"034\",\"038\",\"042\",\"061\",\"067\"]}' --mode eval --dataset_root /content/gdrive/My Drive/comp9517/project/jnet-master/toyexample/DIC-C2DH-HeLa_training --model_file results/DIC-C2DH-HeLa6/model_best_train_train --output_dir results/DIC-C2DH-HeLa6\n","===Vis command===\n","python3 main.py --cuda --resolution_levels '[-2,-1,0]' --dt_bound 6 --images_idx '{\"01\":[],\"02\":[]}' --mode vis --dataset_root /content/gdrive/My Drive/comp9517/project/jnet-master/toyexample/DIC-C2DH-HeLa_test --model_file results/DIC-C2DH-HeLa6/model_best_train_train --output_dir results/DIC-C2DH-HeLa6\n","======\n","net structure:  [[16, 64, 3], [2, 8, 3], [2, 8, 3]]\n","Layer 0 segment 0 channels 64\n","Layer 1 segment 0 channels 64\n","Layer 2 segment 0 channels 64\n","Layer 3 segment 0 channels 64\n","Layer 4 segment 0 channels 64\n","Layer 5 segment 0 channels 64\n","Layer 6 segment 0 channels 64\n","Layer 7 segment 0 channels 64\n","Layer 8 segment 0 channels 64\n","Layer 9 segment 0 channels 64\n","Layer 10 segment 0 channels 64\n","Layer 11 segment 0 channels 64\n","Layer 12 segment 0 channels 64\n","Layer 13 segment 0 channels 64\n","Layer 14 segment 0 channels 64\n","Layer 15 segment 0 channels 64\n","Layer 0 segment 1 channels 72\n","Layer 1 segment 1 channels 72\n","Layer 0 segment 2 channels 80\n","Layer 1 segment 2 channels 80\n","train\n","3e-05\n","/content/gdrive/My Drive/comp9517/project/jnet-master/train.py:57: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n","  err['train_train']+=np.array((loss.data[0],l1_seg,l1_dist))/len(train_dataloader)\n","/content/gdrive/My Drive/comp9517/project/jnet-master/eval.py:28: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n","  err+=np.array((loss.data[0],l1_seg,l1_dist))/len(dataloader)\n","Epoch 1/3000,  {'train_train': array([30.15402424,  0.49080445,  5.22070985]), 'validation_eval': array([29.22527885,  0.48721537,  5.18288302])}\n","3e-05\n","Epoch 2/3000,  {'train_train': array([26.66796309,  0.4596492 ,  4.89152557]), 'validation_eval': array([21.7732892 ,  0.44837064,  4.42090607])}\n","3e-05\n","Epoch 3/3000,  {'train_train': array([22.47509617,  0.43056058,  4.44779348]), 'validation_eval': array([21.12409258,  0.41854513,  4.29886854])}\n","3e-05\n","Epoch 4/3000,  {'train_train': array([20.04723048,  0.40254404,  4.15172918]), 'validation_eval': array([19.65723038,  0.40482804,  4.10728204])}\n","3e-05\n","Epoch 5/3000,  {'train_train': array([18.46113026,  0.39410163,  3.93657972]), 'validation_eval': array([18.17099953,  0.40825065,  3.90508831])}\n","3e-05\n","Epoch 6/3000,  {'train_train': array([17.19345421,  0.40103412,  3.75994568]), 'validation_eval': array([16.42051935,  0.424412  ,  3.67653942])}\n","3e-05\n","Traceback (most recent call last):\n","  File \"main.py\", line 157, in <module>\n","    model=train(model,train_set,validation_set,args)\n","  File \"/content/gdrive/My Drive/comp9517/project/jnet-master/train.py\", line 50, in train\n","    for i,batch in enumerate(train_dataloader):\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 314, in __next__\n","    batch = self.collate_fn([self.dataset[i] for i in indices])\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 314, in <listcomp>\n","    batch = self.collate_fn([self.dataset[i] for i in indices])\n","  File \"/content/gdrive/My Drive/comp9517/project/jnet-master/dataset.py\", line 211, in __getitem__\n","    image,gt_labels=self.transforms[tid](image,gt_labels)\n","  File \"/content/gdrive/My Drive/comp9517/project/jnet-master/augmentation.py\", line 190, in __call__\n","    reflect_grid(grid)\n","  File \"/content/gdrive/My Drive/comp9517/project/jnet-master/augmentation.py\", line 21, in reflect_grid\n","    grid[grid<-1]=-2-grid[grid<-1]\n","KeyboardInterrupt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OO1s26pAI5Jf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":818},"executionInfo":{"status":"ok","timestamp":1595547062099,"user_tz":-600,"elapsed":23652,"user":{"displayName":"Raymond Lu","photoUrl":"","userId":"03985932570144233795"}},"outputId":"19f9dd18-2f64-45f8-fb3a-7d62859fa6ef"},"source":["!python3 main.py --cuda --resolution_levels '[-2,-1,0]' --dt_bound 6 --images_idx '{\"Sequence 1\":[],\"Sequence 2\":[],\"Sequence 3\":[],\"Sequence 4\":[]}' --mode vis --dataset_root ./DIC-C2DH-HeLa --model_file ./results/DIC-C2DH-HeLa6/model_best_train_train --output_dir ./results/segmentations/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["==================================args=============================\n","Namespace(aug_crop_params='[]', aug_elastic_params='[]', aug_intensity_params='[]', aug_rotation=False, aug_rotation_flip=False, batch_size=1, batchnorm_momentum=0.1, cuda=True, dataset_len_multiplier=1, dataset_root='./DIC-C2DH-HeLa', dt_bound=6, images_idx='{\"Sequence 1\":[],\"Sequence 2\":[],\"Sequence 3\":[],\"Sequence 4\":[]}', learning_rate=0.0001, load_dataset_to_ram=0, mode=<Mode.Vis: 'vis'>, model_file='./results/DIC-C2DH-HeLa6/model_best_train_train', non_decreasing_output_file='', num_epochs=5000, num_workers=0, output_dir='./results/segmentations/', resolution_levels='[-2,-1,0]', save_model_frequency=200, structure=None, validation_percentage=0.0)\n","================================end args===========================\n","CUDA: True False\n","net structure:  [[16, 64, 3], [2, 8, 3], [2, 8, 3]]\n","Layer 0 segment 0 channels 64\n","Layer 1 segment 0 channels 64\n","Layer 2 segment 0 channels 64\n","Layer 3 segment 0 channels 64\n","Layer 4 segment 0 channels 64\n","Layer 5 segment 0 channels 64\n","Layer 6 segment 0 channels 64\n","Layer 7 segment 0 channels 64\n","Layer 8 segment 0 channels 64\n","Layer 9 segment 0 channels 64\n","Layer 10 segment 0 channels 64\n","Layer 11 segment 0 channels 64\n","Layer 12 segment 0 channels 64\n","Layer 13 segment 0 channels 64\n","Layer 14 segment 0 channels 64\n","Layer 15 segment 0 channels 64\n","Layer 0 segment 1 channels 72\n","Layer 1 segment 1 channels 72\n","Layer 0 segment 2 channels 80\n","Layer 1 segment 2 channels 80\n","vis\n","Sequence 1_t000, Sequence 1_t001, Sequence 1_t002, Sequence 1_t003, Sequence 1_t004, Sequence 1_t005, Sequence 1_t006, Traceback (most recent call last):\n","  File \"main.py\", line 165, in <module>\n","    eval(model,dataset,args)\n","  File \"/content/gdrive/My Drive/comp9517/project/jnet-master/eval.py\", line 44, in eval\n","    imsave(os.path.join(args.output_dir,\"dist_\"+dataset.get_filename_basis(i)+\".tif\"),img_as_ubyte(dist))\n","  File \"/usr/local/lib/python3.6/dist-packages/imageio/core/functions.py\", line 260, in imwrite\n","    writer.append_data(im)\n","  File \"/usr/local/lib/python3.6/dist-packages/imageio/core/format.py\", line 247, in __exit__\n","    self.close()\n","  File \"/usr/local/lib/python3.6/dist-packages/imageio/core/format.py\", line 262, in close\n","    self._close()\n","  File \"/usr/local/lib/python3.6/dist-packages/imageio/plugins/tifffile.py\", line 306, in _close\n","    self._tf.close()\n","  File \"/usr/local/lib/python3.6/dist-packages/tifffile/tifffile.py\", line 2293, in close\n","    self._fh.close()\n","  File \"/usr/local/lib/python3.6/dist-packages/tifffile/tifffile.py\", line 7052, in close\n","    self._fh.close()\n","KeyboardInterrupt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NNP25UYOqmt-","colab_type":"code","colab":{}},"source":["os.chdir(\"/content/gdrive/My Drive/comp9517/project/jnet-master/results/segmentations\")\n","os.mkdir(\"DIST\")\n","os.mkdir(\"DIST/seq1\")\n","os.mkdir(\"DIST/seq2\")\n","os.mkdir(\"DIST/seq3\")\n","os.mkdir(\"DIST/seq4\")\n","os.mkdir(\"SEG\")\n","os.mkdir(\"SEG/seq1\")\n","os.mkdir(\"SEG/seq2\")\n","os.mkdir(\"SEG/seq3\")\n","os.mkdir(\"SEG/seq4\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ONItFSuMrsr4","colab_type":"code","colab":{}},"source":["import shutil \n","for file in os.listdir(\"./\"):\n","  if file.endswith(\".png\"):\n","    os.remove(file)\n","  elif file.startswith(\"dist\"):\n","    if (\"Sequence 1\" in file):\n","      shutil.move(file,\"DIST/seq1/\"+file)\n","    elif (\"Sequence 2\" in file):\n","      shutil.move(file,\"DIST/seq2/\"+file)\n","    elif (\"Sequence 3\" in file):\n","      shutil.move(file,\"DIST/seq3/\"+file)\n","    else:\n","      shutil.move(file,\"DIST/seq4/\"+file)\n","  elif file.endswith(\".tif\"):\n","    if (\"Sequence 1\" in file):\n","      shutil.move(file,\"SEG/seq1/\"+file)\n","    elif (\"Sequence 2\" in file):\n","      shutil.move(file,\"SEG/seq2/\"+file)\n","    elif (\"Sequence 3\" in file):\n","      shutil.move(file,\"SEG/seq3/\"+file)\n","    else:\n","      shutil.move(file,\"SEG/seq4/\"+file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oVEa-dMesQYt","colab_type":"code","colab":{}},"source":["!python3 main.py --resolution_levels '[-2,-1,0]' --dt_bound 6 --images_idx '{\"Sequence 1\":[],\"Sequence 2\":[],\"Sequence 3\":[],\"Sequence 4\":[]}' --mode vis --dataset_root ./DIC-C2DH-HeLa --model_file ./results/DIC-C2DH-HeLa6/model_best_train_train --output_dir ./results/segmentations/"],"execution_count":null,"outputs":[]}]}